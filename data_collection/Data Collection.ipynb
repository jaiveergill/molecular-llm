{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07aLHp32ESUs",
        "outputId": "3d28dc58-1ffa-4d50-87e7-93f6a71ec03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysmiles\n",
            "  Downloading pysmiles-1.0.2-py2.py3-none-any.whl (22 kB)\n",
            "Collecting pbr (from pysmiles)\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx~=2.0 (from pysmiles)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr, networkx, pysmiles\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "Successfully installed networkx-2.8.8 pbr-5.11.1 pysmiles-1.0.2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "!pip install pysmiles\n",
        "from pysmiles import read_smiles\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exDdyrphEYO2",
        "outputId": "aa908397-6a2a-42dc-c541-8a7676bd9133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratelimit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBd8Peybr2Kg",
        "outputId": "47e1052b-680f-4855-cd8c-195d8aad0e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratelimit\n",
            "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ratelimit\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5893 sha256=80676998074ec899387d67a9a04ab1202424e385876c9548548683bdbc37d328\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/5f/ba/e972a56dcbf5de9f2b7d2b2a710113970bd173c4dcd3d2c902\n",
            "Successfully built ratelimit\n",
            "Installing collected packages: ratelimit\n",
            "Successfully installed ratelimit-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ratelimit import limits\n",
        "\n",
        "import requests\n",
        "TIME_PERIOD = 1   # time period in seconds"
      ],
      "metadata": {
        "id": "iClmjOjBrzNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvCph61fEZPD",
        "outputId": "b45e3322-cb80-4374-981c-c0be4fa50632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4800a610c9b3>:1: DtypeWarning: Columns (2,32,33,35,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/summaryPubChemLarge.csv')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/summaryPubChemLarge.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEVokF5XEhXa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def has_more_chars(string):\n",
        "  count_numbers = 0\n",
        "  count_characters = 0\n",
        "  for character in string:\n",
        "    if character.isdigit():\n",
        "      count_numbers += 1\n",
        "    else:\n",
        "      count_characters += 1\n",
        "  return count_characters > count_numbers\n",
        "\n",
        "def simplify(arr):\n",
        "  new_arr = arr.copy()\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    try:\n",
        "      if 'doi' in str(arr[i]).lower():\n",
        "        new_arr.remove(arr[i])\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "  for i in range(len(new_arr)):\n",
        "    new_arr[i] = str(new_arr[i]).replace(\"<String>\", \"\").replace(\"</String>\", \"\")\n",
        "\n",
        "  f_arr = []\n",
        "  not_allowed = ['Link to all deposited patent identifiers', 'Patents are available for this chemical structure:', '(The corresponding statement to each P-code can be found at the GHS Classification page.)', 'Subscription Services', 'Legacy Depositors']\n",
        "  forbidden = ['©', 'Inc.', 'The GHS information provided by', 'PubMed']\n",
        "  for i in range(len(new_arr)):\n",
        "    if (len(new_arr[i].split(' ')) >= 2 or ' is ' in new_arr[i]) and not new_arr[i].count(':') > 3 and not new_arr[i].count('+') > 3 and not any([f in new_arr[i] for f in forbidden]) and new_arr[i] not in not_allowed:\n",
        "      f_arr.append(new_arr[i])\n",
        "  if len(str.join(' ', f_arr).split(' ')) > 5:\n",
        "    return list(set(f_arr))\n",
        "  else:\n",
        "    return 'None'\n",
        "\n",
        "# @limits(calls=5, period=TIME_PERIOD)\n",
        "def gather_data(cid):\n",
        "  data = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/xml\")\n",
        "  html = BeautifulSoup(data.content, \"xml\")\n",
        "  return simplify(html.find_all(\"String\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvtWHzRMGJeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e2befa6-8015-4442-da2f-17d8a116ee18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'None'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "gather_data(2244)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5luncaPOg50",
        "outputId": "11ce1563-500d-4bad-bf7d-5483117aa43a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
              "<Fault xmlns=\"http://pubchem.ncbi.nlm.nih.gov/pug_view\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema-instance\" xs:schemaLocation=\"http://pubchem.ncbi.nlm.nih.gov/pug_view https://pubchem.ncbi.nlm.nih.gov/pug_view/pug_view.xsd\">\n",
              "<Code>PUGVIEW.ServerBusy</Code>\n",
              "<Message>Too many requests or server too busy</Message>\n",
              "</Fault>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{2244}/xml\")\n",
        "BeautifulSoup(data.content, \"xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtF4hrRkEr3d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "from IPython.display import clear_output\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def scrape_pubchem(df):\n",
        "  df['description'] = np.array([np.nan for i in range(len(df['cid']))])\n",
        "  st = time.time()\n",
        "  good = 0\n",
        "  bad = 0\n",
        "  for i in range(len(df['cid'])):\n",
        "    if good >= 125125:\n",
        "      break\n",
        "    if (i+1) % 10 == 0:\n",
        "      time_diff = (time.time()-st)/60\n",
        "      pct = round((i+1)/len(df), 5)\n",
        "      eta = (time_diff / pct) - time_diff\n",
        "      clear_output()\n",
        "      print(f'Finished {i+1} out of {len(df)}, {round(pct * 100, 2)}% done, Time gone by: {time_diff // 60} hours and {round(time_diff % 60, 2)} minutes, ETA: {eta // 60} hours and {round(eta % 60, 2)} minutes, Good: {good}, Bad:{bad}')\n",
        "\n",
        "    if (i+1) % 5000 == 0:\n",
        "      print('Making checkpoint')\n",
        "      pickle.dump(df, open(f'drive/MyDrive/eda_summary_saves/description_checkpoint.v3.{i+1}.pkl', 'wb'))\n",
        "    x = gather_data(df['cid'][i])\n",
        "    if x != 'None':\n",
        "      df['description'][i] = x\n",
        "      good += 1\n",
        "    else:\n",
        "      bad += 1\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNqmzc2WLHCX"
      },
      "outputs": [],
      "source": [
        "def scrape_pubchem_threaded(df):\n",
        "  df['description'] = np.array([None for i in range(len(df['cid']))])\n",
        "  good = 0\n",
        "  bad = 0\n",
        "  st = time.time()\n",
        "  threads = 25\n",
        "  for i in range(len(df['cid']) // threads):\n",
        "    if i % 100 == 0:\n",
        "      print('saving')\n",
        "      pickle.dump(df, open(f'drive/MyDrive/eda_summary_saves/save{i*200}_threaded.pkl', 'wb'))\n",
        "    time.sleep(0.1)\n",
        "    with ThreadPoolExecutor(threads) as executor:\n",
        "      # submit tasks and collect futures\n",
        "      futures = [executor.submit(gather_data, df['cid'][i]) for i in range(threads)]\n",
        "      # process task results as they are available\n",
        "      for future in as_completed(futures):\n",
        "          # retrieve the result\n",
        "          result = future.result()\n",
        "          if result != 'None':\n",
        "            df['description'][i] = result\n",
        "            good += 1\n",
        "          else:\n",
        "            bad += 1\n",
        "      time_diff = (time.time()-st)/60\n",
        "      pct = round((i+1)/(len(df)//threads), 5)\n",
        "      eta = (time_diff / (pct)) - time_diff\n",
        "      clear_output()\n",
        "      print(f'Finished {i+1} threads out of {len(df)//threads}, {round(pct * 100, 2)}% done\\nTime gone by: {time_diff // 60} hours and {round(time_diff % 60, 2)} minutes, ETA: {eta // 60} hours and {round(eta % 60, 2)} minutes, Good: {good}, Bad:{bad}')\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksls_zGNQo_G"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "from random import random\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from concurrent.futures import as_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxlVGEnQFJ-l"
      },
      "outputs": [],
      "source": [
        "x = scrape_pubchem_threaded(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlnU6gleCi7g"
      },
      "outputs": [],
      "source": [
        "import concurrent\n",
        "ids = [df['cid'][i] for i in range(1000)]\n",
        "with ThreadPoolExecutor(1000) as executor:\n",
        "   executor.map(gather_data, ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zzu-cfPKlCJ"
      },
      "outputs": [],
      "source": [
        "# SuperFastPython.com\n",
        "# example of getting results for tasks as they are completed\n",
        "\n",
        "\n",
        "# start the thread pool\n",
        "with ThreadPoolExecutor(10) as executor:\n",
        "    # submit tasks and collect futures\n",
        "    futures = [executor.submit(gather_data, df['cid'][i]) for i in range(10)]\n",
        "    # process task results as they are available\n",
        "    for future in as_completed(futures):\n",
        "        # retrieve the result\n",
        "        result = future.result()\n",
        "        print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6NMzkkiXgyG"
      },
      "outputs": [],
      "source": [
        "pickle.dump(x, open(f'drive/MyDrive/eda_summary_saves/description_checkpoint_large.pkl', 'wb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgb_0YblVqdi"
      },
      "outputs": [],
      "source": [
        "x = x['description'].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzxfRpfcB40k"
      },
      "outputs": [],
      "source": [
        "x[23]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}