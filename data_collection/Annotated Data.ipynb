{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG81GfSwrvz3",
        "outputId": "eb1281b4-05bc-4c78-ea2a-cad1fb690462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pysmiles\n",
            "  Downloading pysmiles-1.0.2-py2.py3-none-any.whl (22 kB)\n",
            "Collecting pbr (from pysmiles)\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx~=2.0 (from pysmiles)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr, networkx, pysmiles\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "Successfully installed networkx-2.8.8 pbr-5.11.1 pysmiles-1.0.2\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-8aee42ef8d2d>:13: DtypeWarning: Columns (32,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/summaryPubChemAnnotated.csv')\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "!pip install pysmiles\n",
        "from pysmiles import read_smiles\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/summaryPubChemAnnotated.csv')\n",
        "\n",
        "\n",
        "def has_more_chars(string):\n",
        "  count_numbers = 0\n",
        "  count_characters = 0\n",
        "  for character in string:\n",
        "    if character.isdigit():\n",
        "      count_numbers += 1\n",
        "    else:\n",
        "      count_characters += 1\n",
        "  return count_characters > count_numbers\n",
        "\n",
        "def simplify(arr):\n",
        "  new_arr = arr.copy()\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    try:\n",
        "      if 'doi' in str(arr[i]).lower():\n",
        "        new_arr.remove(arr[i])\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "  for i in range(len(new_arr)):\n",
        "    new_arr[i] = str(new_arr[i]).replace(\"<String>\", \"\").replace(\"</String>\", \"\")\n",
        "\n",
        "  f_arr = []\n",
        "  not_allowed = []#'Link to all deposited patent identifiers', 'Patents are available for this chemical structure:', '(The corresponding statement to each P-code can be found at the GHS Classification page.)', 'Subscription Services', 'Legacy Depositors']\n",
        "  forbidden = []#'©', 'Inc.', 'The GHS information provided by', 'PubMed']\n",
        "  for i in range(len(new_arr)):\n",
        "    if (len(new_arr[i].split(' ')) >= 2 or ' is ' in new_arr[i]) and not new_arr[i].count(':') > 3 and not new_arr[i].count('+') > 3 and not any([f in new_arr[i] for f in forbidden]) and new_arr[i] not in not_allowed:\n",
        "      f_arr.append(new_arr[i])\n",
        "  if len(str.join(' ', f_arr).split(' ')) > 10:\n",
        "    return list(set(f_arr))\n",
        "  else:\n",
        "    return 'None'\n",
        "\n",
        "# @limits(calls=5, period=TIME_PERIOD)\n",
        "def gather_data(cid):\n",
        "  data = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/xml\")\n",
        "  html = BeautifulSoup(data.content, \"xml\")\n",
        "  return html.find_all(\"String\")\n",
        "\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "from IPython.display import clear_output\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDGjj4XE6Rg9"
      },
      "outputs": [],
      "source": [
        "def scrape_pubchem(df, start=0, end=1):\n",
        "  df['description'] = np.array([np.nan for i in range(len(df['cid']))])\n",
        "  st = time.time()\n",
        "  good = 0\n",
        "  bad = 0\n",
        "  for i in range(start, end):\n",
        "    if good >= 125125:\n",
        "      break\n",
        "    if (i+1) % 10 == 0:\n",
        "      time_diff = (time.time()-st)/60\n",
        "      pct = round((i-start)/(end-start), 5)\n",
        "      eta = (time_diff / pct) - time_diff\n",
        "      clear_output()\n",
        "      print(f'Finished {(i+1)} out of {(end)}, {round(pct * 100, 2)}% done\\nTime gone by: {time_diff // 60} hours and {round(time_diff % 60, 2)} minutes, ETA: {eta // 60} hours and {round(eta % 60, 2)} minutes, Good: {good}, Bad:{bad} Current CID: {df[\"cid\"][i]}')\n",
        "\n",
        "    if (i+1) % 5000 == 0:\n",
        "      print('Making checkpoint')\n",
        "      # pickle.dump(df, open(f'drive/MyDrive/eda_summary_saves/description_checkpoint.v3.{i+1}.pkl', 'wb'))\n",
        "    x = gather_data(df['cid'][i])\n",
        "\n",
        "    df['description'][i] = x\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LZNZRVe7K5h"
      },
      "outputs": [],
      "source": [
        "def gather_data(cid):\n",
        "  data = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/XML?heading=Record+Description\")\n",
        "  html = BeautifulSoup(data.content, \"xml\")\n",
        "  x = list(set(html.find_all(\"String\")))\n",
        "  for i in range(len(x)):\n",
        "    x[i] = str(x[i]).replace(\"<String>\", \"\").replace(\"</String>\", \"\")\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAND2vSJv_Ll",
        "outputId": "5975ad76-3e9c-45b6-9433-76a330f80de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished 328390 out of 328395, 99.98% done\n",
            "Time gone by: 1.0 hours and 2.92 minutes, ETA: 0.0 hours and 0.01 minutes, Good: 0, Bad:0 Current CID: 168266236\n"
          ]
        }
      ],
      "source": [
        "x = scrape_pubchem(df, start=300000, end=len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjG44KOar8ON"
      },
      "outputs": [],
      "source": [
        "pickle.dump(x, open(f'drive/MyDrive/description_full_300k-end_all_sources.pkl', 'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
